# Synthetic Streamflow Datasets Derived from DOE 9505 for Select Texas Basins

This dataset is generated using a Bayesian Hidden Markov Model (BHMM) trained on the [DOE 9505 streamflow projection ensemble](https://doi.ccs.ornl.gov/dataset/9d3ff396-992d-5bd7-ab02-d21ec6193147). A set of 21,000 streamflow realizations are generated for three river basins in Texas using seven different subsets of the 9505 ensemble.

Basins:
- Colorado River Basin
- Trinity River Basin
- Trinity River Basin

9505 Subsets:
- All Models (All 48 ensemble members)
- Bias Correction - Daymet (The 24 ensemble members which use Daymet bias correction)
- Bias Correction - Livneh (The 24 ensemble members which use Livneh bias correction)
- Downscaling - DBCCA (The 24 ensemble members which use DBCCA downscaling )
- Downscaling - RegCM (The 24 ensemble members which use RegCM downscaling)
- Hydro Model - PRMS (The 24 ensemble members which use the PRMS hydrological model)
- Hydro Model - VIC5 (The 24 ensemble members which use the VIC5 hydrological model)

For each pair of basin and subset (21 total), the following is performed:
1. An annual BHMM is fit to the outlet gage's streamflow for the basin using the ensembles of the subset.
2. A set of 1,000 streamflow realizations is generated using the fit BHMM.
3. Annual streamflow realizations at the outlet gage are disaggregated to monthly time steps across multiple gage locations throughout the basin.
4. The streamflow realizations are bundled into a single NetCDF.

The core files of this archive are the 21 NetCDF files generated from this process, organized into folder by their basin name (e.g., `Colorado/`. In addition to the core files, there is a `data/` folder which contains auxillary data used to generate the dataset. The details of these two parts of the archive are provided below.


## NetCDF File Structure

The NetCDF files containing synthetic streamflow outputs:

### File: `{9505_subset}_{basin}_synthetic_dataset.nc`

#### Dimensions
- **`realization`**: Integer identifier for individual realizations
- **`time_step`**: Monthly time steps (e.g., 1940-01-01 to 2016-12-01)
- **`gage_id`**: Streamflow gage sites (e.g., INA10000, INA20000, etc.)
- **`year`**: Annual time steps for hidden states
- **`hmm_parameter_name`**: HMM parameter labels

#### Data Variables

##### 1. `synthetic_streamflow`
- **Description**: Monthly synthetic streamflow generated from Bayesian HMM.
- **Dimensions**: `[realization, time_step, site]`
- **Units**: acre-feet

##### 2. `annual_wet_dry_state`
- **Description**: HMM hidden states for each year and realization. 0 is dry, 1 is wet. For example if the hidden state at realization 2 and year 2000 is 1, that means the streamflow for that year in that specific realization was emitted from the wet state distribution.
- **Dimensions**: `[realization, year]`
- **Values**: 0 (dry state) or 1 (wet state)

##### 3. `hmm_parameters`
- **Description**: Hidden Markov Model parameters used to generate each realization. The `hmm_parameter_name` dimension contains the labels of the different parameters of the BHMM model that generated the realization.
- **Dimensions**: `[realization, hmm_parameter_name]`

#### Coordinate Variables

##### 1. `realization`
- **Description**: Index for each synthetic realization.
- **Values**: [0, 1, 2, ..., n_realizations-1]

##### 2. `time_step`
- **Description**: Monthly time steps (YYYY-MM-DD).
- **Values**: Datetime strings (e.g., 1940-01-01, 1940-02-01, ...)

##### 3. `gage_id`
- **Description**: Index of streamflow gage IDs used by WRAP.
- **Values**: Gage identifiers (e.g., INA10000, INA20000, INA30000, ...)

##### 4. `year`
- **Description**: Year labels for annual states
- **Values**: Year strings (e.g., "1940", "1941", "1942", ...)

##### 5. `parameter`
- **Description**: Labels of HMM parameters
- **Values**: Parameter names (e.g., transition probabilities, emission parameters)

## `data` folder

The `data` folder contains all the necessary files to reproduce this dataset:

### Directory Structure
```
data/
├── configs/
│   ├── basins.json - Metadata for the basins used in the experiment.
│   ├── ensemble_filters.json - Filters for 9505 ensemble subsets used in the experiment.
│   ├── hmm_synthetic_data_metadata.json - Descriptive metadata for the synthetic streamflow generated by the Bayesian HMM.
│   ├── random_seeds.json - Random seeds used for reproducibility across multiple steps of the experiment.
│   ├── reaches_of_interest.csv - Reaches extracted from the 9505 data for downstream use in analysis.
└── geospatial/
│   └── 9505_shapefiles/ - Shapefiles related to the DOE 9505 dataset.
└── WRAP/basin_wams/ - Water Availability Models used as a basis for historical streamflow.
```

### Configuration Files

**`basins.json`** contains basin metadata used for generating the datset.

**`ensemble_filters.json`** define the different subsets of the 9505 ensemble used for training the BHMM models.

**`hmm_synthetic_data_metadata.json`** contains the metadata for the variables and coordinates in the NetCDF dataset.

**`reaches_of_interest.csv`** lists the specific river reaches (COMIDs) extracted from the 9505 dataset for each basin.

**`random_seeds.json`** contains random seeds used for reproducibility.

**`reaches_of_interest.csv`** contains the reaches in the 9505 data which are downselected for further analysis.

### Geospatial Data

**`9505_shapefiles/`** contains the National Hydrography Dataset (NHD) flowline shapefiles for HUC2 regions 11, 12, and 13, used for associating streamflow reaches with control points. Other data provided by the 9505 datset is also included but not needed for the reproducibility of this dataset. This data was downloaded from the following [hydrosource webpage](https://doi.ccs.ornl.gov/dataset/9d3ff396-992d-5bd7-ab02-d21ec6193147).


### Water Availability Models

**`basin_wams/`** contains the Water Availability Model (WAM) files for each basin. These models contain historical streamflows which are used for prior estimation and temporal/spatial disaggreation.

## Usage Examples

### Load NetCDF file in Python:
This code block requires the installation of the following packages: `xarray`, `netCDF4`, `h5netcdf`
```python
import xarray as xr

# Load a dataset
ds = xr.open_dataset('Colorado/All Models_colorado_synthetic_dataset.nc')

# Access streamflow data
streamflow = ds['synthetic_streamflow'] # [realization, time_step, site]

# Access annual states
annual_states = ds['annual_wet_dry_state'] # [realization, year]

# Access HMM parameters
hmm_params = ds['hmm_parameters'] # [realization, parameter]
```
