# Data Documentation

This dataset contains synthetically generated streamflow realizations for several river basins in Texas.

The dataset is generated using a Bayesian Hidden Markov Model (BHMM) trained on the [DOE 9505 streamflow projection ensemble](https://hydrosource.ornl.gov/data/datasets/9505v3_1/). A set of 1000 streamflow realizations and corresponding outputs from WRAP are generated for three river basins in texas using seven different subsets of the 9505 ensemble.

Basins:
- Colorado River Basin
- Trinity River Basin
- Trinity River Basin

9505 Subsets:
- All Models (All 48 ensemble members)
- Bias Correction - Daymet (The 24 ensemble members which use Daymet bias correction)
- Bias Correction - Livneh (The 24 ensemble members which use Livneh bias correction)
- Downscaling - DBCCA (The 24 ensemble members which use DBCCA downscaling )
- Downscaling - RegCM (The 24 ensemble members which use RegCM downscaling)
- Hydro Model - PRMS (The 24 ensemble members which use the PRMS hydrological model)
- Hydro Model - VIC5 (The 24 ensemble members which use the VIC5 hydrological model)
- Bias Correction - Dayment (The 24 ensemble members which use Daymet bias correction)

For each pair of basin and subset (21 total), the following is performed:
1. A an annual BHMM is fit to the outlet streamflow for the basin using the ensembles of the subset.
2. A set of 1000 streamflow realizations is generated using the fit BHMM.
3. The streamflow realizations are bundled into a single NetCDF.

The core files of this archive are the 21 NetCDF files generated from this process, organized into folder by their basin name (e.g., `Colorado/`. In addition to the core files, there is a `data/` folder which contains the data necessary for reproducing the dataset. The details of these two parts of the archive are provided below


## NetCDF File Structure

The NetCDF files containing synthetic streamflow outputs:

### File: `{9505_subset}_{basin}_synthetic_dataset.nc`

#### Dimensions
- **`realization`**: Integer identifier for individual realizations
- **`time_step`**: Monthly time steps (e.g., 1940-01-01 to 2016-12-01)
- **`gage_id`**: Streamflow gage sites (e.g., INA10000, INA20000, etc.)
- **`year`**: Annual time steps for hidden states
- **`hmm_parameter_name`**: HMM parameter labels

#### Data Variables

##### 1. `synthetic_streamflow`
- **Description**: Monthly synthetic streamflow generated from Bayesian HMM.
- **Dimensions**: `[realization, time_step site]`
- **Units**: acre-feet

##### 2. `annual_wet_dry_state`
- **Description**: HMM hidden states for each year and realization. 0 is dry, 1 is wet. For example if the hidden state at realization 2 and year 2000 is 1, that means the streamflow for that year in that specific realization was emitted from the wet state distribution.
- **Dimensions**: `[realization, year]`
- **Values**: 0 (dry state) or 1 (wet state)

##### 3. `hmm_parameters`
- **Description**: Hidden Markov Model parameters used to generate each realization
- **Dimensions**: `[realization, hmm_parameter_name]`

#### Coordinate Variables

##### 1. `realization`
- **Description**: Index for each synthetic realization.
- **Values**: [0, 1, 2, ..., n_realizations-1]

##### 2. `time_step`
- **Description**: Monthly time steps (YYYY-MM-DD).
- **Values**: Datetime strings (e.g., 1940-01-01, 1940-02-01, ...)

##### 3. `gage_id`
- **Description**: Index of streamflow gage IDs used by WRAP.
- **Values**: Gage identifiers (e.g., INA10000, INA20000, INA30000, ...)

##### 4. `year`
- **Description**: Year labels for annual states
- **Values**: Year strings (e.g., "1940", "1941", "1942", ...)

##### 5. `parameter`
- **Description**: Labels of HMM parameters
- **Values**: Parameter names (e.g., transition probabilities, emission parameters)

## `data` folder

The `data` folder contains all the necessary files to reproduce this dataset:

### Directory Structure
```
data/
├── configs/
│   ├── basins.json - Metadata for the basins used in the experiment.
│   ├── ensemble_filters.json - Filters for 9505 ensemble subsets used in the experiment.
│   ├── hmm_synthetic_data_metadata.json - Descriptive metadata for the synthetic streamflow generated by the Bayesian HMM.
│   ├── random_seeds.json - Random seeds used for reproducibility across multiple steps of the experiment.
│   ├── reaches_of_interest.csv - Reaches extracted from the 9505 data for downstream use in analysis.
└── geospatial/
│   └── 9505_shapefiles/ - Shapefiles related to the DOE 9505 dataset.

```

### Configuration Files

**`basins.json`** contains metadata for the basins with the following attributes:
- `reach_id`: The name of the reach in the 9505 data which has been associated to the outflow gage.

**`ensemble_filters.json`** define the different subsets of the 9505 ensemble used for training the BHMM models.

**`reaches_of_interest.csv`** lists the specific river reaches (COMIDs) extracted from the 9505 dataset for each basin.

### Geospatial Data

**`9505_shapefiles/`** contains the National Hydrography Dataset (NHD) flowline shapefiles for HUC2 regions 11, 12, and 13, used for associating streamflow reaches with control points. Other data provided by the 9505 datset is also included, but not needed for the reproducibility of this dataset. This data was downloaded from the [hydrosource webpage](https://hydrosource.ornl.gov/data/datasets/9505v3_1/).


## Usage Examples

### Load NetCDF file in Python:
This code block requires the installation of the following packages: `xarray`, `netCDF4`, `h5netcdf`
```python
import xarray as xr

# Load a dataset
ds = xr.open_dataset('Colorado/All Models_colorado_synthetic_dataset.nc')

# Access streamflow data
streamflow = ds['synthetic_streamflow'] # [realization, time_step, site]

# Access annual states
annual_states = ds['annual_wet_dry_state'] # [realization, year]

# Access HMM parameters
hmm_params = ds['hmm_parameters'] # [realization, parameter]
```
